# -*- coding: utf-8 -*-
"""IR_RandomForest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1O1krrtXBDHesf5y9rEMeUZlWyirBSnR2
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings("ignore")
from sklearn.preprocessing import MinMaxScaler

from sklearn.metrics import f1_score
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

training_data = pd.read_csv("/content/drive/My Drive/Information Retrival End Sem Kaggle/train.csv")
testing_data = pd.read_csv("/content/drive/My Drive/Information Retrival End Sem Kaggle/test_x.csv")
val_data = pd.read_csv("/content/drive/My Drive/Information Retrival End Sem Kaggle/val.csv")

x_train_rf = training_data[['2', '3', '4', '5', '6', '7', '8','10', '11', '12', '13',
       '15', '16', '17', '18', '19', '20', '21', '22', '23','25',
       '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37',
       '40', '41', '42', '43', '44', '45', '46']]

x_train_rf.shape

y_train_rf = training_data[['relevance']]

x_val_rf = val_data[['2', '3', '4', '5', '6', '7', '8','10', '11', '12', '13',
       '15', '16', '17', '18', '19', '20', '21', '22', '23','25',
       '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37',
       '40', '41', '42', '43', '44', '45', '46']]

y_val_rf = val_data[['relevance']]

x_test_rf = testing_data[['2', '3', '4', '5', '6', '7', '8','10', '11', '12', '13',
       '15', '16', '17', '18', '19', '20', '21', '22', '23','25',
       '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37',
       '40', '41', '42', '43', '44', '45', '46']]

scaler = StandardScaler()

x_train_rf = scaler.fit_transform(x_train_rf)
x_val_rf = scaler.transform(x_val_rf)
x_test_rf = scaler.transform(x_test_rf)

import xgboost as xgb

x_train_xg = xgb.DMatrix(np.asmatrix(x_train_rf), label=y_train_rf)
x_final_test_xg = xgb.DMatrix(np.asmatrix(x_test_rf))

x_test_xg = xgb.DMatrix(np.asmatrix(x_val_rf), label=y_val_rf) ##this is validation data


x_train_rf.shape

y_train_rf.shape

params = {
   'n_estimators':100,
   'max_depth': 80 ,  
   'objective': 'multi:softprob',  
   'num_class': 3,
} 


clf = xgb.train(params, x_train, num_round = 1000 )

predstion = clf.predict(x_test_xg)
predictions = np.asarray([np.argmax(line) for line in predstion])

print(f1_score(y_val_rf, predictions, average='macro'))

final_test_data = bst.predict(x_final_test_xg)

final_test_data
xgb_predictions_final = np.asarray([np.argmax(line) for line in final_test_data])

xgb_predictions_final




string = "row_id"+","+"relevance"+"\n"
for i in range(xgb_predictions_final.size):
  string = string + str(i) +"," + str(xgb_predictions_final[i]) +"\n"

with open('/content/drive/My Drive/Information Retrival End Sem Kaggle/xgboost_cv_54_last.csv', 'w') as f:
  f.write(string[:-1])

f.close()

"""Random Forest"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings("ignore")
from sklearn.preprocessing import MinMaxScaler

from sklearn.metrics import f1_score
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

training_data = pd.read_csv("/content/drive/My Drive/Information Retrival End Sem Kaggle/train.csv")
testing_data = pd.read_csv("/content/drive/My Drive/Information Retrival End Sem Kaggle/test_x.csv")
val_data = pd.read_csv("/content/drive/My Drive/Information Retrival End Sem Kaggle/val.csv")

x_train_rf = training_data[['2', '3', '4', '5', '6', '7', '8','10', '11', '12', '13',
       '15', '16', '17', '18', '19', '20', '21', '22', '23','25',
       '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37',
       '40', '41', '42', '43', '44', '45', '46']]

y_train_rf = training_data[['relevance']]

x_val_rf = val_data[['2', '3', '4', '5', '6', '7', '8','10', '11', '12', '13',
       '15', '16', '17', '18', '19', '20', '21', '22', '23','25',
       '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37',
       '40', '41', '42', '43', '44', '45', '46']]

y_val_rf = val_data[['relevance']]

x_test_rf = testing_data[['2', '3', '4', '5', '6', '7', '8','10', '11', '12', '13',
       '15', '16', '17', '18', '19', '20', '21', '22', '23','25',
       '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37',
       '40', '41', '42', '43', '44', '45', '46']]

scaler = MinMaxScaler()
x_train_rf = scaler.fit_transform(x_train_rf)
x_val_rf = scaler.transform(x_val_rf)
x_test_rf = scaler.transform(x_test_rf)

from sklearn.ensemble import RandomForestClassifier

clf = RandomForestClassifier(n_estimators=1500,max_depth=80)

clf.fit(x_train_rf,y_train_rf)

y_pred_val = clf.predict(x_val_rf)

print(accuracy_score(y_val_rf , y_pred_val))
print(f1_score(y_val_rf, y_pred_val, average='macro'))



y_pred_test = clf.predict(x_test_rf)

string = "row_id"+","+"relevance"+"\n"
for i in range(xgb_predictions_final.size):
  string = string + str(i) +"," + str(y_pred_test[i]) +"\n"

with open('/content/drive/My Drive/Information Retrival End Sem Kaggle/randomforest_cv_44.csv', 'w') as f:
  f.write(string[:-1])

f.close





